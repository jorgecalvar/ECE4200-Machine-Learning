{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECE4200 - Kaggle competition\n",
    "### Jorge Calvar (jc2767)\n",
    "\n",
    "This notebook has been executed with only 1000 training samples to be able to hand in a notebook that has run completely.\n",
    "\n",
    "However, the actual notebook used for the competition was executed with more samples. The number of samples can be modified in the Parameters section below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "We import necessary libraries that are used through the whole project.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import spectrogram"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:30:55.969175Z",
     "iopub.execute_input": "2021-11-18T21:30:55.969513Z",
     "iopub.status.idle": "2021-11-18T21:30:57.105071Z",
     "shell.execute_reply.started": "2021-11-18T21:30:55.969416Z",
     "shell.execute_reply": "2021-11-18T21:30:57.104115Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "TRY_TREE = True\n",
    "TRY_LOGISTIC = True\n",
    "TRY_NB = True   # Naive Bayes\n",
    "TRY_SVM = True\n",
    "TRY_BAGGING = True\n",
    "TRY_ADABOOST = True\n",
    "TRY_NN = True\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "TRAIN_DIR = Path('kaggle/input/spoken-digit-pair-recognition/train/train_new')\n",
    "TEST_DIR = Path('kaggle/input/spoken-digit-pair-recognition/test/test_new')\n",
    "WORKING_DIR = Path('kaggle/working')\n",
    "\n",
    "OUTPUT_MODEL = False\n",
    "LOAD_SAVED_MODEL = True"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:31:50.606862Z",
     "iopub.execute_input": "2021-11-18T21:31:50.607190Z",
     "iopub.status.idle": "2021-11-18T21:31:50.612320Z",
     "shell.execute_reply.started": "2021-11-18T21:31:50.607156Z",
     "shell.execute_reply": "2021-11-18T21:31:50.611490Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_labels = pd.read_csv('kaggle/input/spoken-digit-pair-recognition/train.csv', index_col='ID')\n",
    "train_labels.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:33:20.855690Z",
     "iopub.execute_input": "2021-11-18T21:33:20.855982Z",
     "iopub.status.idle": "2021-11-18T21:33:20.945860Z",
     "shell.execute_reply.started": "2021-11-18T21:33:20.855951Z",
     "shell.execute_reply": "2021-11-18T21:33:20.945255Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    Label\nID       \n0      21\n1      32\n2      31\n3      31\n4      41",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sample_sub = pd.read_csv('kaggle/input/spoken-digit-pair-recognition/sample_sub.csv', index_col='ID')\n",
    "sample_sub.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:33:21.006718Z",
     "iopub.execute_input": "2021-11-18T21:33:21.007665Z",
     "iopub.status.idle": "2021-11-18T21:33:21.043511Z",
     "shell.execute_reply.started": "2021-11-18T21:33:21.007614Z",
     "shell.execute_reply": "2021-11-18T21:33:21.042608Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    Label\nID       \n0      21\n1      21\n2      21\n3      21\n4      21",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_files = []\n",
    "for d in [TRAIN_DIR, TEST_DIR]:\n",
    "    max_file = 0\n",
    "    for f in d.iterdir():\n",
    "        i = int(f.name[f.name.index('_')+1:-4])\n",
    "        max_file = np.max([max_file, i])\n",
    "    max_files.append(max_file)\n",
    "print(f'Max train file: {max_files[0]}')\n",
    "print(f'Max test file: {max_files[1]}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:33:21.204396Z",
     "iopub.execute_input": "2021-11-18T21:33:21.204768Z",
     "iopub.status.idle": "2021-11-18T21:33:24.873179Z",
     "shell.execute_reply.started": "2021-11-18T21:33:21.204730Z",
     "shell.execute_reply": "2021-11-18T21:33:24.872318Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train file: 89999\n",
      "Max test file: 24749\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_audio(i, train=True):\n",
    "    dir_to_look = TRAIN_DIR if train else TEST_DIR\n",
    "    file = dir_to_look / f'train_{i}.wav'\n",
    "    _, data = wavfile.read(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_dataframe_to_numpy(df):\n",
    "    for i in range(6000):\n",
    "        df[f'x_{i}'] = df['data'].apply(lambda r: r[i])\n",
    "    del df['data']\n",
    "    array_final = df.to_numpy()\n",
    "    return array_final \n",
    "\n",
    "\n",
    "def try_model(model, X_train, X_val, y_train, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    acc_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    acc_test = accuracy_score(y_val, model.predict(X_val))\n",
    "    return acc_train, acc_test\n",
    "\n",
    "\n",
    "def try_models(models, X_train, X_val, y_train, y_val):\n",
    "    df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        acc_train, acc_test = try_model(model, X_train, X_val, y_train, y_val)\n",
    "        df.loc[len(df), ['Model', 'Train accuracy', 'Validation accuracy']] = [model, acc_train, acc_test]\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:31:55.213860Z",
     "iopub.execute_input": "2021-11-18T21:31:55.214418Z",
     "iopub.status.idle": "2021-11-18T21:31:55.228048Z",
     "shell.execute_reply.started": "2021-11-18T21:31:55.214370Z",
     "shell.execute_reply": "2021-11-18T21:31:55.226752Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "n_batch = np.arange(90000)\n",
    "np.random.shuffle(n_batch)\n",
    "n_batch = n_batch[:N_SAMPLES]\n",
    "\n",
    "audios = [get_audio(i) for i in n_batch]\n",
    "labels = [train_labels.at[i, 'Label'] for i in n_batch]\n",
    "\n",
    "df_x = pd.DataFrame(index=n_batch, data={'data': audios, 'label': labels})\n",
    "\n",
    "array_final = convert_dataframe_to_numpy(df_x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:33:25.878132Z",
     "iopub.execute_input": "2021-11-18T21:33:25.878820Z",
     "iopub.status.idle": "2021-11-18T21:33:44.525154Z",
     "shell.execute_reply.started": "2021-11-18T21:33:25.878760Z",
     "shell.execute_reply": "2021-11-18T21:33:44.524340Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(array_final[:, 1:], array_final[:, 0], test_size=0.1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T21:33:44.526742Z",
     "iopub.execute_input": "2021-11-18T21:33:44.526969Z",
     "iopub.status.idle": "2021-11-18T21:33:44.604951Z",
     "shell.execute_reply.started": "2021-11-18T21:33:44.526936Z",
     "shell.execute_reply": "2021-11-18T21:33:44.604095Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.570261Z",
     "iopub.execute_input": "2021-11-18T01:50:18.570482Z",
     "iopub.status.idle": "2021-11-18T01:50:18.762709Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.570455Z",
     "shell.execute_reply": "2021-11-18T01:50:18.761819Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_tree_models():\n",
    "    models = set()\n",
    "    for criterion in ['gini', 'entropy']:\n",
    "        models.add(DecisionTreeClassifier(criterion=criterion, max_depth=None))\n",
    "        for max_depth in range(1, 13):\n",
    "            models.add(DecisionTreeClassifier(criterion=criterion, max_depth=max_depth))\n",
    "    return models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.765358Z",
     "iopub.execute_input": "2021-11-18T01:50:18.765657Z",
     "iopub.status.idle": "2021-11-18T01:50:18.771264Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.765619Z",
     "shell.execute_reply": "2021-11-18T01:50:18.7705Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRY_TREE:\n",
    "    models_tree = get_tree_models()\n",
    "    result_tree = try_models(models_tree, X_train, X_val, y_train, y_val)\n",
    "    result_tree.to_csv(WORKING_DIR / 'tree_models.csv')\n",
    "    result_tree.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.772311Z",
     "iopub.execute_input": "2021-11-18T01:50:18.772854Z",
     "iopub.status.idle": "2021-11-18T01:50:18.784943Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.772822Z",
     "shell.execute_reply": "2021-11-18T01:50:18.783917Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtained the best result with 11 max_depth. The validation accuracy does not even reach 50%. Although this makes it better than a random model, it is far from a good one. After a few variations of decision tree models, it was concluded that they were not the best approach and the time was used to focus on other models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.78649Z",
     "iopub.execute_input": "2021-11-18T01:50:18.786805Z",
     "iopub.status.idle": "2021-11-18T01:50:18.797919Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.786771Z",
     "shell.execute_reply": "2021-11-18T01:50:18.796674Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_logistic_models():\n",
    "    models = set()\n",
    "    N = np.array(range(0,15))\n",
    "    lamb = 0.00001*(4**N)\n",
    "    for l in lamb:\n",
    "        models.add(LogisticRegression(C=1/l, solver='sag', max_iter=1000))\n",
    "    return models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.799377Z",
     "iopub.execute_input": "2021-11-18T01:50:18.800251Z",
     "iopub.status.idle": "2021-11-18T01:50:18.809507Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.800198Z",
     "shell.execute_reply": "2021-11-18T01:50:18.80872Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRY_LOGISTIC:\n",
    "    models_logistic = get_logistic_models()\n",
    "    result_logistic = try_models(models_logistic, X_train, X_val, y_train, y_val)\n",
    "    result_logistic.to_csv(WORKING_DIR / 'logistic_models.csv')\n",
    "    result_logistic.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.811152Z",
     "iopub.execute_input": "2021-11-18T01:50:18.811738Z",
     "iopub.status.idle": "2021-11-18T01:50:18.828334Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.811681Z",
     "shell.execute_reply": "2021-11-18T01:50:18.827474Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain the very good training accuracies of 100% and relatively good validation accuracies close to 90%. This makes logistic regression a very good approach, specially considering the simplicity of the final model, which is just a set coefficients for the input variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_naive_bayes_models():\n",
    "    models = set()\n",
    "    models.add(GaussianNB())\n",
    "    return models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "if TRY_NB:\n",
    "    models_nb = get_naive_bayes_models()\n",
    "    result_nb = try_models(models_nb, X_train, X_val, y_train, y_val)\n",
    "    result_nb.to_csv(WORKING_DIR / 'naive_bayes_models.csv')\n",
    "    result_nb.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performance of the Naive Bayes model is terrible. The training and validation accuracy are close to 20%, which is what we would expect of a random model. This is because Naive Bayes is an extremely simple model that allows for little room of flexibility of the predictive function. We also concentrate on other models after seeing this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.82978Z",
     "iopub.execute_input": "2021-11-18T01:50:18.830172Z",
     "iopub.status.idle": "2021-11-18T01:50:18.840626Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.830138Z",
     "shell.execute_reply": "2021-11-18T01:50:18.839877Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_svm_models():\n",
    "    models = set()\n",
    "    n = np.array(range(20))\n",
    "    C = 2**n\n",
    "    for c in C:\n",
    "        for degree in range(1, 6):\n",
    "            models.add(SVC(C=c, kernel='poly', degree=degree))\n",
    "        models.add(SVC(C=c, kernel='rbf'))\n",
    "    return models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.842556Z",
     "iopub.execute_input": "2021-11-18T01:50:18.843489Z",
     "iopub.status.idle": "2021-11-18T01:50:18.854029Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.843387Z",
     "shell.execute_reply": "2021-11-18T01:50:18.852974Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRY_SVM:\n",
    "    models_svm = get_svm_models()\n",
    "    result_svm = try_models(models_svm, X_train, X_val, y_train, y_val)\n",
    "    result_svm.to_csv(WORKING_DIR / 'svm_models.csv')\n",
    "    result_svm.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.855421Z",
     "iopub.execute_input": "2021-11-18T01:50:18.855723Z",
     "iopub.status.idle": "2021-11-18T01:50:18.867797Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.855688Z",
     "shell.execute_reply": "2021-11-18T01:50:18.866977Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM has been the best performing model of this notebook. The downside is that takes very long to train, so few combinations can be tried to tweak the model. I reached a training and validation accuracy of 100% and 90.909% testing accuracy in the kaggle leaderboard.\n",
    "\n",
    "The decrease in accuracy in the kaggle leaderboard is due to the fact that there are no label 43 samples in the training set, so it fails to predict them. However, several techniques have been applied to solve this problem in the Pytorch notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bagging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.869092Z",
     "iopub.execute_input": "2021-11-18T01:50:18.869686Z",
     "iopub.status.idle": "2021-11-18T01:50:18.905465Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.869634Z",
     "shell.execute_reply": "2021-11-18T01:50:18.90472Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_bagging_models():\n",
    "    models = set()\n",
    "    n_max = 12\n",
    "    indices = 2**np.array(range(0,n_max))\n",
    "    for i in indices:\n",
    "        models.add(BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy'), n_estimators=i))\n",
    "    return models\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.906758Z",
     "iopub.execute_input": "2021-11-18T01:50:18.907049Z",
     "iopub.status.idle": "2021-11-18T01:50:18.912757Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.907015Z",
     "shell.execute_reply": "2021-11-18T01:50:18.912012Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRY_BAGGING:\n",
    "    models_bagging = get_bagging_models()\n",
    "    result_bagging = try_models(models_bagging, X_train, X_val, y_train, y_val)\n",
    "    result_bagging.to_csv(WORKING_DIR / 'bagging_models.csv')\n",
    "    result_bagging.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.913864Z",
     "iopub.execute_input": "2021-11-18T01:50:18.914211Z",
     "iopub.status.idle": "2021-11-18T01:50:18.925917Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.914181Z",
     "shell.execute_reply": "2021-11-18T01:50:18.924896Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\jorge\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance with bagging is not bad but it is not better than SVMs or Logistic Regression models. Near 80% validation accuracy. It has an incredible downside: which is that it takes very long to train."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AdaBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.927132Z",
     "iopub.execute_input": "2021-11-18T01:50:18.927382Z",
     "iopub.status.idle": "2021-11-18T01:50:18.938664Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.927348Z",
     "shell.execute_reply": "2021-11-18T01:50:18.937779Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_adaboost_models():\n",
    "    models = set()\n",
    "    indices = 2**np.array(range(0,n_max))\n",
    "    maximum_depth = [10, 20, 50, 100]\n",
    "    for i in indices:\n",
    "        for md in maximum_depth:\n",
    "            models.add(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', maximum_depth=md), n_estimators=i))\n",
    "        models.add(AdaBoostClassifier(base_estimator=RandomForestClassifier(criterion='entropy', maximum_depth=50, n_estimators=10), n_estimators=i))\n",
    "    return models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.940274Z",
     "iopub.execute_input": "2021-11-18T01:50:18.940721Z",
     "iopub.status.idle": "2021-11-18T01:50:18.952494Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.94064Z",
     "shell.execute_reply": "2021-11-18T01:50:18.951719Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if TRY_ADABOOST:\n",
    "    models_adaboost = get_adaboost_models()\n",
    "    result_adaboost = try_models(models_adaboost, X_train, X_val, y_train, y_val)\n",
    "    result_adaboost.to_csv(WORKING_DIR / 'adaboost_models.csv')\n",
    "    result_adaboost.sort_values('Validation accuracy', ascending=False).head(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.953877Z",
     "iopub.execute_input": "2021-11-18T01:50:18.95423Z",
     "iopub.status.idle": "2021-11-18T01:50:18.970077Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.9542Z",
     "shell.execute_reply": "2021-11-18T01:50:18.969239Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance with Adaboost was similar to bagging in the validation test. Training accuracy, however, has improved. Still, SVMs remain the best model so far."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.971506Z",
     "iopub.execute_input": "2021-11-18T01:50:18.972037Z",
     "iopub.status.idle": "2021-11-18T01:50:18.992881Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.971999Z",
     "shell.execute_reply": "2021-11-18T01:50:18.991762Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# if TRY_NN:\n",
    "model_nn = MLPClassifier(hidden_layer_sizes=(500, 500))\n",
    "acc_train, acc_test = try_model(model_nn, X_train, X_val, y_train, y_val)\n",
    "print(acc_train)\n",
    "print(acc_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:18.994219Z",
     "iopub.execute_input": "2021-11-18T01:50:18.994564Z",
     "iopub.status.idle": "2021-11-18T01:50:18.999438Z",
     "shell.execute_reply.started": "2021-11-18T01:50:18.99448Z",
     "shell.execute_reply": "2021-11-18T01:50:18.998655Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note:** Neural networks are developed more using pytorch in the final submission notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "if OUTPUT_MODEL:\n",
    "\n",
    "    if LOAD_SAVED_MODEL:\n",
    "        import pickle\n",
    "        with open(WORKING_DIR / 'model_svm.bin', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    else:\n",
    "        #DEFINE OR CREATE THE FINAL MODEL HERE\n",
    "        model = SVC(C=256, kernel='poly', degree=2)\n",
    "        model.fit(X_train, y_train)\n",
    "        with open(WORKING_DIR / 'model_svm.bin', 'wb') as f:\n",
    "            f.write(pickle.dumps(model))\n",
    "\n",
    "    df_test = pd.DataFrame(columns=['data'])\n",
    "    df_test.index.name = 'ID'\n",
    "\n",
    "    for i in range(24750):\n",
    "        df_test.loc[i, 'data'] = get_audio(i)\n",
    "\n",
    "    df_test.head()\n",
    "    X_test = convert_dataframe_to_numpy(df_test)\n",
    "\n",
    "    y_test = model.predict(X_test)\n",
    "\n",
    "    df = pd.DataFrame(index=df_test.index, columns=['Label'])\n",
    "    df['Label'] = y_test\n",
    "    df.to_csv(WORKING_DIR / 'submission.csv')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-18T01:50:20.369302Z",
     "iopub.execute_input": "2021-11-18T01:50:20.369582Z",
     "iopub.status.idle": "2021-11-18T01:50:20.517831Z",
     "shell.execute_reply.started": "2021-11-18T01:50:20.369546Z",
     "shell.execute_reply": "2021-11-18T01:50:20.516924Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Annex:** Frequency analysis of a random train set signal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "i = np.random.randint(0, 90000)\n",
    "file = TRAIN_DIR / f'train_{i}.wav'\n",
    "\n",
    "fs, x = wavfile.read(file)\n",
    "n_samples = len(x)\n",
    "print(f'Sample frequency: {fs} / N Samples: {n_samples}')\n",
    "\n",
    "\n",
    "# Spectre with fft\n",
    "\n",
    "X = (fft(x)/n_samples)[:n_samples//2]\n",
    "f_x = np.linspace(0, 1/2, n_samples//2)*fs\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f_x, np.abs(X))\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(f'Spectre of {file.name}')\n",
    "\n",
    "# Spectrogram\n",
    "    \n",
    "f_x, t_x, Sxx = spectrogram(x, fs=fs)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(t_x, f_x, Sxx)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "print(f'Spectrogram shape: {Sxx.shape}')"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Annex:** Exploring how fft works"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "freq = 10\n",
    "\n",
    "fs = 100\n",
    "t = np.arange(0, 1, 1/fs)\n",
    "x = np.sin(2*np.pi*freq*t)\n",
    "\n",
    "# n samples\n",
    "n_samples = len(x)\n",
    "print(f'N samples: {len(x)}')\n",
    "\n",
    "# Draw\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, x)\n",
    "plt.title(f'Sine {freq}Hz')\n",
    "\n",
    "# Spectre\n",
    "\n",
    "X = (fft(x)/n_samples)[:n_samples//2]\n",
    "x_f = np.linspace(0, 1/2, n_samples//2)*fs\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_f, np.abs(X))\n",
    "plt.title('Spectre')\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}